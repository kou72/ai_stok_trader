"""
ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨å¯è¦–åŒ–
"""
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import torch


class Evaluator:
    """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model, device):
        """
        Parameters:
        -----------
        model : nn.Module
            è©•ä¾¡ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
        device : torch.device
            ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹
        """
        self.model = model
        self.device = device
    
    def evaluate(self, train_loader, val_loader, test_loader):
        """
        7. è©•ä¾¡
        
        Parameters:
        -----------
        train_loader, val_loader, test_loader : DataLoader
            å„ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        
        Returns:
        --------
        results : dict
            è©•ä¾¡çµæœ
        """
        print("\n" + "=" * 80)
        print("7. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        print("=" * 80)
        
        self.model.eval()
        
        results = {}
        
        for name, loader in [('è¨“ç·´', train_loader), ('æ¤œè¨¼', val_loader), ('ãƒ†ã‚¹ãƒˆ', test_loader)]:
            pred, target, pred_binary = self._evaluate_loader(loader)
            metrics = self._calculate_metrics(target, pred_binary)
            
            results[name] = {
                'predictions': pred,
                'targets': target,
                'predictions_binary': pred_binary,
                'metrics': metrics
            }
            
            self._print_metrics(name, metrics, target, pred_binary)
        
        return results
    
    def _evaluate_loader(self, data_loader):
        """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã§è©•ä¾¡"""
        all_predictions = []
        all_targets = []
        
        with torch.no_grad():
            for X_batch, y_batch in data_loader:
                X_batch = X_batch.to(self.device)
                outputs = self.model(X_batch)
                all_predictions.extend(outputs.cpu().numpy())
                all_targets.extend(y_batch.numpy())
        
        predictions = np.array(all_predictions)
        targets = np.array(all_targets)
        predictions_binary = (predictions > 0.5).astype(int)
        
        return predictions, targets, predictions_binary
    
    @staticmethod
    def _calculate_metrics(targets, predictions_binary):
        """è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—"""
        return {
            'accuracy': accuracy_score(targets, predictions_binary),
            'precision': precision_score(targets, predictions_binary, zero_division=0),
            'recall': recall_score(targets, predictions_binary, zero_division=0),
            'f1': f1_score(targets, predictions_binary, zero_division=0),
            'confusion_matrix': confusion_matrix(targets, predictions_binary)
        }
    
    @staticmethod
    def _print_metrics(name, metrics, targets, predictions_binary):
        """è©•ä¾¡çµæœã®è¡¨ç¤º"""
        cm = metrics['confusion_matrix']
        
        if name == 'ãƒ†ã‚¹ãƒˆ':
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: åŸºæº–è¶…=1ã®æ­£ç­”ç‡ã‚’è©³ç´°è¡¨ç¤º
            print(f"\n{'='*80}")
            print(f"ã€{name}ãƒ‡ãƒ¼ã‚¿è©•ä¾¡çµæœã€‘")
            print(f"{'='*80}")
            
            actual_1_total = np.sum(targets == 1)
            correct_1 = cm[1][1]
            recall = correct_1 / max(actual_1_total, 1)
            
            print(f"\n  ğŸ¯ åŸºæº–è¶…=1ã®äºˆæ¸¬çµæœ:")
            print(f"    å®Ÿéš›ã«ä¸Šæ˜‡ã—ãŸæ—¥æ•°:     {actual_1_total} æ—¥")
            print(f"    æ­£ã—ãäºˆæ¸¬ã§ããŸæ—¥æ•°:   {correct_1} æ—¥")
            print(f"    æ­£ç­”ç‡ (å†ç¾ç‡):        {recall:.4f} ({recall*100:.2f}%)")
            
            print(f"\n  æ··åŒè¡Œåˆ—:")
            print(f"                äºˆæ¸¬0   äºˆæ¸¬1")
            print(f"    å®Ÿéš›0    {cm[0][0]:6d}  {cm[0][1]:6d}")
            print(f"    å®Ÿéš›1    {cm[1][0]:6d}  {cm[1][1]:6d}")
            
            print(f"\n  å‚è€ƒ:")
            print(f"    é©åˆç‡ (Precision): {metrics['precision']:.4f} (äºˆæ¸¬ãŒå½“ãŸã‚‹ç¢ºç‡)")
            print(f"    å…¨ä½“ã®æ­£è§£ç‡:       {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
            
        else:
            # è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: ç°¡æ˜“è¡¨ç¤ºï¼ˆéå­¦ç¿’ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
            recall = metrics['recall']
            print(f"\nã€{name}ãƒ‡ãƒ¼ã‚¿ã€‘å…¨ä½“æ­£è§£ç‡: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%) | åŸºæº–è¶…=1ã®æ­£ç­”ç‡: {recall:.4f} ({recall*100:.2f}%)")
    
    def visualize(self, results, train_losses, val_losses, epochs):
        """
        8. çµæœã®å¯è¦–åŒ–
        
        Parameters:
        -----------
        results : dict
            è©•ä¾¡çµæœ
        train_losses, val_losses : list
            è¨“ç·´ãƒ»æ¤œè¨¼ã®Losså±¥æ­´
        epochs : int
            ã‚¨ãƒãƒƒã‚¯æ•°
        """
        print("\n" + "=" * 80)
        print("8. çµæœã®å¯è¦–åŒ–")
        print("=" * 80)
        
        plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Hiragino Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # ã‚°ãƒ©ãƒ•1: å­¦ç¿’æ›²ç·š
        self._plot_learning_curve(train_losses, val_losses, epochs)
        
        # ã‚°ãƒ©ãƒ•2: åŸºæº–è¶…=1ã®æ­£ç­”ç‡
        self._plot_recall_summary(results)
    
    @staticmethod
    def _plot_learning_curve(train_losses, val_losses, epochs):
        """å­¦ç¿’æ›²ç·š"""
        fig, ax = plt.subplots(figsize=(10, 6))
        ax.plot(range(1, epochs+1), train_losses, label='è¨“ç·´Loss', marker='o')
        ax.plot(range(1, epochs+1), val_losses, label='æ¤œè¨¼Loss', marker='s')
        ax.set_xlabel('Epoch')
        ax.set_ylabel('Loss')
        ax.set_title('å­¦ç¿’æ›²ç·šï¼ˆLossï¼‰', fontsize=14, fontweight='bold')
        ax.legend()
        ax.grid(True, alpha=0.3)
        plt.tight_layout()
        plt.show()
    
    @staticmethod
    def _plot_recall_summary(results):
        """åŸºæº–è¶…=1ã®æ­£ç­”ç‡ï¼ˆå†ç¾ç‡ï¼‰ã®ã‚µãƒãƒªãƒ¼"""
        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 6))
        
        # ã‚°ãƒ©ãƒ•1: åŸºæº–è¶…=1ã®æ­£ç­”ç‡ï¼ˆå†ç¾ç‡ï¼‰ã®æ¯”è¼ƒ
        datasets = ['è¨“ç·´', 'æ¤œè¨¼', 'ãƒ†ã‚¹ãƒˆ']
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆã®åŸºæº–è¶…=1ã®æ­£ç­”ç‡ã‚’è¨ˆç®—
        recalls = []
        actual_counts = []
        correct_counts = []
        
        for name in datasets:
            cm = results[name]['metrics']['confusion_matrix']
            actual_1 = cm[1][0] + cm[1][1]  # å®Ÿéš›ã«1ã ã£ãŸç·æ•°
            correct_1 = cm[1][1]  # æ­£ã—ãäºˆæ¸¬
            recall = correct_1 / max(actual_1, 1)
            
            recalls.append(recall)
            actual_counts.append(actual_1)
            correct_counts.append(correct_1)
        
        x = np.arange(len(datasets))
        bars = ax1.bar(x, recalls, color=['skyblue', 'lightgreen', 'lightcoral'])
        
        ax1.set_xlabel('ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', fontsize=12)
        ax1.set_ylabel('æ­£ç­”ç‡ï¼ˆå†ç¾ç‡ï¼‰', fontsize=12)
        ax1.set_title('åŸºæº–è¶…=1ã®æ­£ç­”ç‡', fontsize=14, fontweight='bold')
        ax1.set_xticks(x)
        ax1.set_xticklabels(datasets)
        ax1.set_ylim(0, 1.0)
        ax1.grid(True, alpha=0.3, axis='y')
        
        # æ•°å€¤ãƒ©ãƒ™ãƒ«
        for i, (bar, recall) in enumerate(zip(bars, recalls)):
            height = bar.get_height()
            ax1.text(bar.get_x() + bar.get_width()/2., height,
                    f'{recall*100:.1f}%',
                    ha='center', va='bottom', fontsize=12, fontweight='bold')
        
        # ã‚°ãƒ©ãƒ•2: åŸºæº–è¶…=1ã®è©³ç´°ï¼ˆä»¶æ•°ï¼‰
        x_pos = np.arange(len(datasets))
        width = 0.35
        
        bars1 = ax2.bar(x_pos - width/2, actual_counts, width, label='å®Ÿéš›ã«ä¸Šæ˜‡', color='gold')
        bars2 = ax2.bar(x_pos + width/2, correct_counts, width, label='æ­£ã—ãäºˆæ¸¬', color='lightcoral')
        
        ax2.set_xlabel('ãƒ‡ãƒ¼ã‚¿ã‚»ãƒƒãƒˆ', fontsize=12)
        ax2.set_ylabel('æ—¥æ•°', fontsize=12)
        ax2.set_title('åŸºæº–è¶…=1ã®è©³ç´°', fontsize=14, fontweight='bold')
        ax2.set_xticks(x_pos)
        ax2.set_xticklabels(datasets)
        ax2.legend()
        ax2.grid(True, alpha=0.3, axis='y')
        
        # æ•°å€¤ãƒ©ãƒ™ãƒ«
        for bars in [bars1, bars2]:
            for bar in bars:
                height = bar.get_height()
                ax2.text(bar.get_x() + bar.get_width()/2., height,
                        f'{int(height)}',
                        ha='center', va='bottom', fontsize=10, fontweight='bold')
        
        plt.tight_layout()
        plt.show()