"""
ãƒ¢ãƒ‡ãƒ«ã®è©•ä¾¡ã¨å¯è¦–åŒ–
"""
import numpy as np
import matplotlib.pyplot as plt
from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix
import torch


class Evaluator:
    """ãƒ¢ãƒ‡ãƒ«è©•ä¾¡ãƒ»å¯è¦–åŒ–ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, model, device):
        """
        Parameters:
        -----------
        model : nn.Module
            è©•ä¾¡ã™ã‚‹ãƒ¢ãƒ‡ãƒ«
        device : torch.device
            ä½¿ç”¨ãƒ‡ãƒã‚¤ã‚¹
        """
        self.model = model
        self.device = device
    
    def evaluate(self, train_loader, val_loader, test_loader):
        """
        7. è©•ä¾¡
        
        Parameters:
        -----------
        train_loader, val_loader, test_loader : DataLoader
            å„ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼
        
        Returns:
        --------
        results : dict
            è©•ä¾¡çµæœ
        """
        print("\n" + "=" * 80)
        print("7. ãƒ¢ãƒ‡ãƒ«è©•ä¾¡")
        print("=" * 80)
        
        self.model.eval()
        
        results = {}
        
        for name, loader in [('è¨“ç·´', train_loader), ('æ¤œè¨¼', val_loader), ('ãƒ†ã‚¹ãƒˆ', test_loader)]:
            pred, target, pred_binary = self._evaluate_loader(loader)
            metrics = self._calculate_metrics(target, pred_binary)
            
            results[name] = {
                'predictions': pred,
                'targets': target,
                'predictions_binary': pred_binary,
                'metrics': metrics
            }
            
            self._print_metrics(name, metrics, target, pred_binary)
        
        return results
    
    def _evaluate_loader(self, data_loader):
        """ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ€ãƒ¼ã§è©•ä¾¡"""
        all_predictions = []
        all_targets = []
        
        with torch.no_grad():
            for X_batch, y_batch in data_loader:
                X_batch = X_batch.to(self.device)
                outputs = self.model(X_batch)
                all_predictions.extend(outputs.cpu().numpy())
                all_targets.extend(y_batch.numpy())
        
        predictions = np.array(all_predictions)
        targets = np.array(all_targets)
        predictions_binary = (predictions > 0.5).astype(int)
        
        return predictions, targets, predictions_binary
    
    @staticmethod
    def _calculate_metrics(targets, predictions_binary):
        """è©•ä¾¡æŒ‡æ¨™ã®è¨ˆç®—"""
        return {
            'accuracy': accuracy_score(targets, predictions_binary),
            'precision': precision_score(targets, predictions_binary, zero_division=0),
            'recall': recall_score(targets, predictions_binary, zero_division=0),
            'f1': f1_score(targets, predictions_binary, zero_division=0),
            'confusion_matrix': confusion_matrix(targets, predictions_binary)
        }
    
    @staticmethod
    def _print_metrics(name, metrics, targets, predictions_binary):
        """è©•ä¾¡çµæœã®è¡¨ç¤º"""
        cm = metrics['confusion_matrix']
        
        if name == 'ãƒ†ã‚¹ãƒˆ':
            # ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿: åŸºæº–è¶…=1ã®æ­£ç­”ç‡ã‚’è©³ç´°è¡¨ç¤º
            print(f"\n{'='*80}")
            print(f"ã€{name}ãƒ‡ãƒ¼ã‚¿è©•ä¾¡çµæœã€‘")
            print(f"{'='*80}")
            
            actual_1_total = np.sum(targets == 1)
            correct_1 = cm[1][1]
            recall = correct_1 / max(actual_1_total, 1)
            
            print(f"\n  ğŸ¯ åŸºæº–è¶…=1ã®äºˆæ¸¬çµæœ:")
            print(f"    å®Ÿéš›ã«ä¸Šæ˜‡ã—ãŸæ—¥æ•°:     {actual_1_total} æ—¥")
            print(f"    æ­£ã—ãäºˆæ¸¬ã§ããŸæ—¥æ•°:   {correct_1} æ—¥")
            print(f"    æ­£ç­”ç‡ (å†ç¾ç‡):        {recall:.4f} ({recall*100:.2f}%)")
            
            print(f"\n  æ··åŒè¡Œåˆ—:")
            print(f"                äºˆæ¸¬0   äºˆæ¸¬1")
            print(f"    å®Ÿéš›0    {cm[0][0]:6d}  {cm[0][1]:6d}")
            print(f"    å®Ÿéš›1    {cm[1][0]:6d}  {cm[1][1]:6d}")
            
            print(f"\n  å‚è€ƒ:")
            print(f"    é©åˆç‡ (Precision): {metrics['precision']:.4f} (äºˆæ¸¬ãŒå½“ãŸã‚‹ç¢ºç‡)")
            print(f"    å…¨ä½“ã®æ­£è§£ç‡:       {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%)")
            
        else:
            # è¨“ç·´ãƒ»æ¤œè¨¼ãƒ‡ãƒ¼ã‚¿: ç°¡æ˜“è¡¨ç¤ºï¼ˆéå­¦ç¿’ãƒã‚§ãƒƒã‚¯ç”¨ï¼‰
            recall = metrics['recall']
            print(f"\nã€{name}ãƒ‡ãƒ¼ã‚¿ã€‘å…¨ä½“æ­£è§£ç‡: {metrics['accuracy']:.4f} ({metrics['accuracy']*100:.2f}%) | åŸºæº–è¶…=1ã®æ­£ç­”ç‡: {recall:.4f} ({recall*100:.2f}%)")
    
    def visualize(self, results, train_losses, val_losses, train_precisions, val_precisions, epochs):
        """
        8. çµæœã®å¯è¦–åŒ–
        
        Parameters:
        -----------
        results : dict
            è©•ä¾¡çµæœ
        train_losses, val_losses : list
            è¨“ç·´ãƒ»æ¤œè¨¼ã®Losså±¥æ­´
        train_precisions, val_precisions : list
            è¨“ç·´ãƒ»æ¤œè¨¼ã®çš„ä¸­ç‡å±¥æ­´
        epochs : int
            ã‚¨ãƒãƒƒã‚¯æ•°
        """
        print("\n" + "=" * 80)
        print("8. çµæœã®å¯è¦–åŒ–")
        print("=" * 80)
        
        plt.rcParams['font.sans-serif'] = ['MS Gothic', 'Yu Gothic', 'Hiragino Sans']
        plt.rcParams['axes.unicode_minus'] = False
        
        # 2è»¸ã‚°ãƒ©ãƒ•ã§æå¤±ã¨çš„ä¸­ç‡ã‚’åŒæ™‚ã«è¡¨ç¤º
        fig, ax1 = plt.subplots(figsize=(12, 6))
        
        # å·¦è»¸: Loss
        color1 = 'tab:blue'
        ax1.set_xlabel('Epoch', fontsize=12)
        ax1.set_ylabel('Loss', color=color1, fontsize=12)
        line1 = ax1.plot(range(1, epochs+1), train_losses, color=color1, marker='o', label='è¨“ç·´Loss', linewidth=2)
        line2 = ax1.plot(range(1, epochs+1), val_losses, color='tab:cyan', marker='s', label='æ¤œè¨¼Loss', linewidth=2)
        ax1.tick_params(axis='y', labelcolor=color1)
        ax1.grid(True, alpha=0.3)
        
        # å³è»¸: çš„ä¸­ç‡
        ax2 = ax1.twinx()
        color2 = 'tab:red'
        ax2.set_ylabel('çš„ä¸­ç‡ (%)', color=color2, fontsize=12)
        line3 = ax2.plot(range(1, epochs+1), [p*100 for p in train_precisions], color=color2, marker='^', label='è¨“ç·´çš„ä¸­ç‡', linewidth=2)
        line4 = ax2.plot(range(1, epochs+1), [p*100 for p in val_precisions], color='tab:orange', marker='v', label='æ¤œè¨¼çš„ä¸­ç‡', linewidth=2)
        ax2.tick_params(axis='y', labelcolor=color2)
        ax2.set_ylim(0, 100)
        
        # å‡¡ä¾‹ã‚’çµ±åˆ
        lines = line1 + line2 + line3 + line4
        labels = [l.get_label() for l in lines]
        ax1.legend(lines, labels, loc='upper right', fontsize=10)
        
        plt.title('æå¤±ã¨çš„ä¸­ç‡ã®æ¨ç§»', fontsize=14, fontweight='bold')
        plt.tight_layout()
        plt.show()